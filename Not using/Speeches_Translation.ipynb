{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e19a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: torch in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (2.7.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (4.52.4)\n",
      "Requirement already satisfied: pipeline in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (0.1.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (3.8.7)\n",
      "Requirement already satisfied: captum in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (0.8.0)\n",
      "Requirement already satisfied: shap in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (0.48.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 18)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (1.5.1)\n",
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (0.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (80.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from huggingface_hub[hf_xet]->-r requirements.txt (line 11)) (1.1.5)\n",
      "Requirement already satisfied: click in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from sacremoses->-r requirements.txt (line 13)) (8.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (2.11.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from spacy->-r requirements.txt (line 15)) (3.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from shap->-r requirements.txt (line 17)) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from shap->-r requirements.txt (line 17)) (1.7.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from shap->-r requirements.txt (line 17)) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from shap->-r requirements.txt (line 17)) (0.61.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from shap->-r requirements.txt (line 17)) (3.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 18)) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 18)) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 18)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 18)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 18)) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.6.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from numba>=0.54->shap->-r requirements.txt (line 17)) (0.44.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 15)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 15)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 15)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 8)) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 15)) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 15)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 15)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 15)) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 15)) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 15)) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from scikit-learn->shap->-r requirements.txt (line 17)) (3.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.8.4)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 15)) (1.2.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 15)) (3.0.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 15)) (1.17.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 18)) (0.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\franc\\documents\\github\\nlp_project\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 15)) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bb1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = pd.read_excel(r\"C:\\Users\\franc\\Documents\\GitHub\\nlp_project\\Final Dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fb5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model to translate from spanish to english, so it can be implemented correctly to the final model\n",
    "\n",
    "language_model_name = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "language_tokenizer = MarianTokenizer.from_pretrained(language_model_name)\n",
    "language_model = MarianMTModel.from_pretrained(language_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821f24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts):\n",
    "    \"\"\"\n",
    "    Translates a list of texts from a source language to a target language using a transformer-based translation model.\n",
    "\n",
    "    Parameters:\n",
    "        texts (list of str): List of input text strings to be translated.\n",
    "\n",
    "    Returns:\n",
    "        list of str: List of translated text strings corresponding to each input text, in the same order.\n",
    "    \"\"\"\n",
    "            \n",
    "    inputs = language_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = language_model.generate(**inputs)\n",
    "    return [language_tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60342736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using part of a speech in the dataset, to see the translation\n",
    "\n",
    "spanish_texts = [\"Hola a todos.\", \"Yo soy el león.\", \"Yo también los amo.\", \"Viva la libertad, carajo.\"]\n",
    "translated_texts = translate(spanish_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c7e0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, everyone.',\n",
       " \"I'm the lion.\",\n",
       " 'I love you too.',\n",
       " 'Long live the fucking freedom.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d136f6",
   "metadata": {},
   "source": [
    "The model for translating the speeches seems accurate and for the objective of this project it is considered sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "091e3ce4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Translate all speeches to english\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m translated_texts = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_speeches\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\franc\\Documents\\GitHub\\nlp_project\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\franc\\Documents\\GitHub\\nlp_project\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\franc\\Documents\\GitHub\\nlp_project\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Translate all speeches to english\n",
    "\n",
    "translated_texts = Parallel(n_jobs=-1)(delayed(translate)(text) for text in df_speeches['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new tranlated column\n",
    "\n",
    "df_speeches['content_en'] = translated_texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
